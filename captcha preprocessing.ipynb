{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f182e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_new = r'C:/Users/utkar/Desktop/dl/captcha_dataset_new/test_dataset/'\n",
    "path_train_new = r'C:/Users/utkar/Desktop/dl/captcha_dataset_new/train_dataset/'\n",
    "path_test = r'C:/Users/utkar/Desktop/dl/captcha_dataset1/test_dataset/'\n",
    "path_train = r'C:/Users/utkar/Desktop/dl/captcha_dataset1/train_dataset/'\n",
    "\n",
    "\n",
    "label = ['2', '3', '4', '5', '6', '7', '8', '9', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G1', 'H1', 'J1', 'K1', 'L1', 'M1', \n",
    "         'P1', 'Q1', 'R1', 'S1', 'T1', 'U1', 'V1', 'W1', 'X1', 'Y1', 'a', 'b', 'c', 'd', 'e', 'f', 'h', 'j', 'k', 'm', \n",
    "         'n', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n",
    "\n",
    "horizontal_flip_label = [ '8',  'A1', 'H1', 'M1', 'T1', 'U1', 'V1', 'W1', 'X1', 'Y1','v', 'w', 'x']\n",
    "\n",
    "l = ['2', '3', '4', '5', '6', '7', '9', 'B1', 'C1', 'D1', 'E1', 'F1', 'G1', 'J1', 'K1', 'L1', 'P1', 'Q1', 'R1', 'S1', 'a',\n",
    "     'b', 'c', 'd', 'e', 'f', 'h', 'j', 'k', 'm', 'n', 'p', 'q', 'r', 's', 't', 'u', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making directory for each alphabet\n",
    "for i in label:\n",
    "    path = path_train_new + i\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting number of image for each label\n",
    "for i in label:\n",
    "    a = 0\n",
    "    for file in os.listdir(path_dataset+'/'+i):\n",
    "        a+=1\n",
    "    print(i, a)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and testing dataset\n",
    "train_path = r'C:/Users/utkar/Desktop/ML/pytorch/presentData/captcha_dataset/train_dataset/'\n",
    "test_path = r'C:/Users/utkar/Desktop/ML/pytorch/presentData/captcha_dataset/test_dataset/'\n",
    " \n",
    "\n",
    "for i in label:\n",
    "    path = train_path + i + '/'\n",
    "    #print('path', path)\n",
    "    a = 0\n",
    "    for file in os.listdir(path):\n",
    "        print(file)\n",
    "        shutil.move(path+file, test_path+i)\n",
    "        a += 1\n",
    "        if a == 40:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in label:\n",
    "    path = path_test + i + '/'\n",
    "    for file in os.listdir(path):\n",
    "        a+=1\n",
    "        print(a)\n",
    "        img = cv2.imread(path + file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "        cv2.imwrite(path+file, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deed283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/utkar/Desktop/dl/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3458118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# captcha image resizing\n",
    "c = 0\n",
    "b = np.random.randint(1, 75)\n",
    "print(b)\n",
    "w, h = 220, 50\n",
    "for i, file in enumerate(os.listdir(path)):\n",
    "    if i == b*c:\n",
    "        img = cv2.imread(path+file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        a, b = img.shape\n",
    "        center = a/2, b/2\n",
    "        x = center[1] - w/2 # width\n",
    "        y = center[0] - h/2 # height\n",
    "        d = 170\n",
    "        img = img[int(y):int(y+h), int(x):int(x+220)]\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "        c += 1\n",
    "        if c == 40:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18229191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr2rgb2gray(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return img\n",
    "\n",
    "def centerCrop(img):\n",
    "    w, h = 220, 50\n",
    "    a, b = img.shape\n",
    "    center = a/2, b/2\n",
    "    x = center[1] - w/2 # width\n",
    "    y = center[0] - h/2 # height\n",
    "    img = img[int(y):int(y+50), int(x):int(x+220)]\n",
    "    return img\n",
    "\n",
    "cap_label = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "# since folder with name 'a' and 'A' is considered same I name 'A' as 'A1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18458c",
   "metadata": {},
   "source": [
    "### splitting letters in captcha image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = r'C:/Users/utkar/Desktop/ML/pytorch/presentData/captcha_dataset/'\n",
    "a = 0\n",
    "for file in os.listdir(path):\n",
    "    img = cv2.imread(path+file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    a, b = img.shape\n",
    "    center = a/2, b/2\n",
    "    x = center[1] - w/2 # width\n",
    "    y = center[0] - h/2 # height\n",
    "    img = img[int(y):int(y+50), int(x):int(x+220)]\n",
    "    list_break = coordinates(img)\n",
    "    for i in range(5):\n",
    "        img_crop = img[int(y):int(y+h), int(list_break[2*i]): int(list_break[2*i+1])]\n",
    "        img_crop = cv2.resize(img_crop, (35, 35))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52d21a",
   "metadata": {},
   "source": [
    "### making directory to save image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in label:\n",
    "    os.makedirs('C:/Users/utkar/Desktop/ML/pytorch/presentData/captcha_dataset/test_dataset/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a56ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aadff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a8ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
